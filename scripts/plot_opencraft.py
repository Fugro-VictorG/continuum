import math
import time
import argparse
import sys
import logging
import subprocess
import datetime
import os

from io import StringIO

import seaborn as sbn
import matplotlib.pyplot as plt
import matplotlib.ticker as mtick
import matplotlib.patches as mpatches
import numpy as np
import pandas as pd

from matplotlib.ticker import FuncFormatter, ScalarFormatter
from matplotlib.ticker import NullFormatter
from matplotlib.ticker import MaxNLocator

def enable_logging(verbose):
    """Enable logging"""
    # Set parameters
    new_level = logging.INFO
    if verbose:
        new_level = logging.DEBUG

    new_format = "[%(asctime)s %(filename)20s:%(lineno)4s - %(funcName)25s() ] %(message)s"
    logging.basicConfig(format=new_format, level=new_level, datefmt="%Y-%m-%d %H:%M:%S")

    logging.info("Logging has been enabled")

def execute(command):
    """Execute a process using the subprocess library,
    and return the output/error or the process

    Args:
        command (list(str)): Command to be executed.

    Returns:
        (list(str), list(str)): Return the output and error generated by this process.
    """
    logging.info(" ".join(command))

    with subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE) as process:
        output = [line.decode("utf-8") for line in process.stdout.readlines()]
        error = [line.decode("utf-8") for line in process.stderr.readlines()]

    return output, error

class Experiment:
    """Experiment template / super class"""

    def __init__(self, resume):
        self.resume = resume
        self.runs = []

    def check_resume(self):
        """If the resume argument is given, get the first x log files >= the resume date,
        and use their output instead of re-running the experiment.
        """
        if self.resume is None:
            return

        log_location = "./logs/" + self.log_directory
        logs = [f for f in os.listdir(log_location) if f.endswith(".log")]
        logs.sort()
        exp_i = 0

        for log in logs:
            splits = log.split("_")
            dt = splits[0] + "_" + splits[1]
            dt = datetime.datetime.strptime(dt, "%Y-%m-%d_%H:%M:%S")

            if dt >= self.resume:
                path = os.path.join(log_location, log)
                logging.info("File %s for experiment run %i", path, exp_i)

                with open(path, "r", encoding="utf-8") as f:
                    output = f.readlines()
                    f.close()

                self.runs[exp_i]["output"] = output
                exp_i += 1

                # We have all logs needed
                if exp_i == len(self.runs):
                    break

    def run_commands(self):
        """Execute all generated commands"""
        for run in self.runs:
            if run["command"] == []:
                continue

            # Skip runs where we got output with --resume
            if run["output"] is not None:
                logging.info("Skip command: %s", " ".join(run["command"]))
                continue

            output, error = execute(run["command"])

            logging.debug("------------------------------------")
            logging.debug("OUTPUT")
            logging.debug("------------------------------------")
            logging.debug("\n%s", "".join(output[-5:]))

            if error != []:
                logging.debug("------------------------------------")
                logging.debug("ERROR")
                logging.debug("------------------------------------")
                logging.debug("\n%s", "".join(error))
                sys.exit()

            logging.debug("------------------------------------")

            # Get output from log file
            logpath = output[0].rstrip().split("and file ")[-1]
            with open(logpath, "r", encoding="utf-8") as f:
                output = f.readlines()
                run["output"] = output
                f.close()

class LatencyCPUVariation(Experiment):
    """Experiment:
    Deploy 1 cloud worker and 1 endpoint, and vary latency from 0ms to 100ms in steps of 10
    Also vary the CPU cores / memory from 0.5 (GB) to 8.0 (GB)

    So:
    - Run with minimal cloud deployment
    - Change latency from 0ms to 100ms between cloud and endpoint in steps of 10ms
    - Change application CPU and memory from 0.5 to 8.0 in power of 2 steps
    """

    def __init__(self, resume):
        Experiment.__init__(self, resume)

        self.latency = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]

        # CPU x quota: 0.5 | 1.0 | 2.0 | 4.0 | 8.0
        self.cpu = [2]#[1, 1, 2, 4, 8]
        self.memory = [2]#[0.5, 1.0, 2.0, 4.0, 8.0]
        self.quota = [1]#[0.5, 1.0, 1.0, 1.0, 1.0]
        self.log_directory = "mc_latency_0-500_9core"

        self.y = None

    def __repr__(self):
        """Returns this string when called as print(object)"""
        return """
APP                     opencraft
LATENCY                 %s
CPU CORES               %s
MEMORY (GB)             %s
QUOTA                   %s""" % (
            ",".join(str(latency) for latency in self.latency),
            ",".join(str(cpu) for cpu in self.cpu),
            ",".join(str(memory) for memory in self.memory),
            ",".join(str(quota) for quota in self.quota),
        )

    def generate(self):
        """Generate commands to run the benchmark based on the current settings"""
        # Differ in deployment modes
        for latency in self.latency:
            for cpu, memory, quota in zip(self.cpu, self.memory, self.quota):
                cpu_quota = cpu * quota
                if cpu_quota != memory:
                    logging.error("ERROR: cpu x quota (%f) != memory (%f)", cpu_quota, memory)
                    sys.exit()

                if cpu_quota >= 1:
                    cpu_str = "%s00" % (int(cpu_quota))
                elif cpu_quota < 1:
                    cpu_str = "0%s" % (int(cpu_quota * 100))

                config = "cloud_%ims_cpu%s.cfg" % (latency, cpu_str)
                command = [
                    "python3",
                    "continuum.py",
                    "-v",
                    "configuration/experiment_latency_var_oc/" + config,
                ]
                command = [str(c) for c in command]

                run = {
                    "cpu_quota_memory": cpu_quota,
                    "network_latency": latency,
                    "command": command,
                    "output": None,
                    "latency": None,
                }
                self.runs.append(run)

    def parse_output(self):
        """For all runs, get the worker runtime"""
        for run in self.runs:
            # # Get the line containing the metrics
            # i = -10
            # for i, line in enumerate(run["output"]):
            #     if "Output in csv format" in line:
            #         break

            # # Get output based on type of run
            # raw_results = run["output"][i:][1]

            # # Get endpoint output, parse into dataframe
            # results1 = [x.split(",") for x in raw_results.split("\\n")]
            # results2 = [sub[1:] for sub in results1]
            # results_dict = dict(zip(results2[0], results2[1]))
            # for key in results_dict:
            #     run[key] = float(results_dict[key])

            for i, line in enumerate(run["output"]):
                if "Measurer spawned" in line:
                    break 
            
            # Response times
            run["dig_times"] = []
            run["place_times"] = []
            raw_results = run["output"][(i + 1):]
            i = 0
            while "----------------------------" not in raw_results[i]:
                if "Msr dig:" in raw_results[i]: 
                    measured_value = str.strip(raw_results[i].split('Msr dig:')[1])
                    run["dig_times"].append(measured_value)
                elif "Msr place:" in raw_results[i]:
                    measured_value = str.strip(raw_results[i].split('Msr place:')[1])
                    run["place_times"].append(measured_value)
                i += 1


    def plot2(self):
        x = [run["network_latency"] for run in self.runs if run["cpu_quota_memory"] == 2]
        x = [int(elem) * 5 for elem in x]
        y1 = [run["dig_times"] for run in self.runs]
        y2 = [run["place_times"] for run in self.runs]
        y1 = [[int(x) for x in lst] for lst in y1]
        y2 = [[int(x) for x in lst] for lst in y2]

        def pad_list(lst, length):
                return lst + [float('nan')] * (length - len(lst))

        # Pad sublists in y1 and y2
        max_length_y1 = max(len(sublist) for sublist in y1)
        max_length_y2 = max(len(sublist) for sublist in y2)
        y1_padded = [pad_list(sublist, max_length_y1) for sublist in y1]
        y2_padded = [pad_list(sublist, max_length_y2) for sublist in y2]

        df = pd.DataFrame({
            "Block digging": y1_padded,
            "Block placement": y2_padded,
            "Network latency": x,
        })
    
        medy1 = [np.nanmedian(np.array(sublist)) for sublist in df["Block digging"]]
        medy2 = [np.nanmedian(np.array(sublist)) for sublist in df["Block placement"]]

        plt.plot(x, medy1, linewidth=1.5, label='Median (Block digging)', marker='o')
        #plt.plot(x, medy2, linewidth=1.5, label='Median (Block placement)', marker='o')

        plt.yticks(medy1)
        plt.xticks(x)
        plt.grid(True)
        t = time.strftime("%Y-%m-%d_%H-%M-%S", time.gmtime())
        plt.savefig("./logs/test_%s.pdf" % (t), bbox_inches="tight")



    def plot(self):
        """Plot the results from executed runs"""
        # set width of bar
        plt.rcParams.update({"font.size": 19})

        x = [run["network_latency"] for run in self.runs if run["cpu_quota_memory"] == 2]

        for cpu, quota in zip(self.cpu, self.quota):
            cpu_quota = cpu * quota
            y1 = [run["dig_times"] for run in self.runs if run["cpu_quota_memory"] == cpu_quota]
            y2 = [run["place_times"] for run in self.runs if run["cpu_quota_memory"] == cpu_quota]

            y1 = [[int(x) for x in lst] for lst in y1]
            y2 = [[int(x) for x in lst] for lst in y2]
            x = [int(elem) * 5 for elem in x]

            # Function to pad sublists with NaNs to ensure equal length
            def pad_list(lst, length):
                return lst + [float('nan')] * (length - len(lst))

            # Pad sublists in y1 and y2
            max_length_y1 = max(len(sublist) for sublist in y1)
            max_length_y2 = max(len(sublist) for sublist in y2)
            y1_padded = [pad_list(sublist, max_length_y1) for sublist in y1]
            y2_padded = [pad_list(sublist, max_length_y2) for sublist in y2]

            df = pd.DataFrame({
                "Block digging": y1_padded,
                "Block placement": y2_padded,
                "Network latency": x,
            })

            medy1 = [np.nanmedian(np.array(sublist)) for sublist in df["Block digging"]]
            medy2 = [np.nanmedian(np.array(sublist)) for sublist in df["Block placement"]]

            df_exploded = df.explode(column=["Block digging", "Block placement"])

            df_melted = pd.melt(df_exploded, id_vars=["Network latency"], var_name="Action", value_name="Values")

            #df_melted = df_melted.dropna()

            # Create boxplot using Seaborn
            logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)
            plt.figure(figsize=(10, 6))
            box_positions = sbn.boxplot(x="Network latency", y="Values", hue="Action", data=df_melted, dodge=True, palette="pastel").get_xticks()
            plt.plot([pos-0.2 for pos in box_positions], medy1, linewidth=1.5, label='Median (Block digging)')
            plt.plot([pos+0.2 for pos in box_positions], medy2, linewidth=1.5, label='Median (Block placement)')
            # plt.plot(
            #     x_axis,
            #     meany2,
            #     ':',
            #     linewidth=1.5,
            # )
            plt.yticks(np.arange(0, 1801, 200))
            plt.ylim(-100, 1800)
            #plt.xlim(0, 500)
            plt.xlabel("Network latency [ms]")
            plt.ylabel("Response times [ms]")
            plt.grid(True)

            t = time.strftime("%Y-%m-%d_%H:%M:%S", time.gmtime())
            plt.savefig("./logs/LatencyCPUVariation_%s.pdf" % (t), bbox_inches="tight")
            # plt.clf()
            # q1 = []
            # q3 = []
            # for sublist in df["Block digging"]:
            #     x3, x1 = np.nanpercentile(sublist, [75, 25])
            #     q1.append(x1)
            #     q3.append(x3)

            # iqr = [xi - yi for xi, yi in zip(q3, q1)]
            # stdevy1 = [np.nanstd(np.array(sublist)) for sublist in df["Block digging"]]
            # plt.plot(x, iqr)
            # plt.grid(True)
            # t = time.strftime("%Y-%m-%d_%H:%M:%S", time.gmtime())
            # plt.savefig("./logs/OCLatencyStdev_%s.pdf" % (t), bbox_inches="tight")

    def plot1(self):
        """Plot the results from executed runs"""
        # set width of bar
        plt.rcParams.update({"font.size": 22})
        _, ax1 = plt.subplots(figsize=(12, 6))

        x = [run["network_latency"] for run in self.runs if run["cpu_quota_memory"] == 2]

        for cpu, quota in zip(self.cpu, self.quota):
            cpu_quota = cpu * quota
            y1 = [run["response_time_dig_mean"] for run in self.runs if run["cpu_quota_memory"] == cpu_quota]
            y2 = [run["response_time_place_mean"] for run in self.runs if run["cpu_quota_memory"] == cpu_quota]

            ax1.plot(
                x,
                y1,
                linewidth=3.0,
                marker="o",
                markersize=12,
                label="Block digging",
            )

            ax1.plot(
                x,
                y2,
                linewidth=3.0,
                marker="o",
                markersize=12,
                label="Block placement"
            )

        # Set y axis: latency
        ax1.set_ylabel("Average response time [ms]")
        ax1.set_yscale("linear")
        ax1.set_ylim(10, 300)
        ax1.set_yticks(np.arange(0, 325, 25))

        ax1.set_xlabel("Network latency between cloud and endpoint [ms]")
        ax1.set_xlim(0, 100)
        ax1.set_xticks(np.arange(0, 110, 10))

        ax1.legend(loc="upper left", framealpha=1.0, bbox_to_anchor=[0, 1])

        #ax1.axhline(y=10, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=25, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=50, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=75, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=100, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=125, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=150, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=175, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=200, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=225, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=250, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=275, color="k", linestyle="-", linewidth=1, alpha=0.5)

        # Save
        t = time.strftime("%Y-%m-%d_%H:%M:%S", time.gmtime())
        plt.savefig("./logs/OCLatencyCPUVariation_%s.pdf" % (t), bbox_inches="tight")

    def print_result(self):
        """Print results of runs as text"""
        for run in self.runs:
            logging.info(
                "Tick duration mean: %5i ms | \
                Tick duration median: %5i ms | \
                Tick duration stdev: %5i ms | \
CPU Cores x Quota == Memory: %5f | \
Response time dig mean: %5i ms | \
Response time dig median: %5i ms | \
Response time dig stdev: %5i | \
Response time place mean: %5i ms | \
Response time place median: %5i ms | \
Response time place stdev: %5i",
                run["ticks_mean"],
                run["ticks_median"],
                run["ticks_stdev"],
                run["cpu_quota_memory"],
                run["response_time_dig_mean"],
                run["response_time_dig_median"],
                run["response_time_dig_stdev"],
                run["response_time_place_mean"],
                run["response_time_place_median"],
                run["response_time_place_stdev"]
            )
            
class EndpointScaling(Experiment):
    """Experiment:
    Deploy a cloud worker with an Opencraft server, and vary the number of endpoints per run, in increments of 25.
    """

    def __init__(self, resume):
        Experiment.__init__(self, resume)

        self.modes = ["linear"]#, "fixed"]
        self.cores = [4]
        self.endpoints = [20, 40, 60, 80]#, 100, 125, 150]
        self.log_directory = "oc_endpoint_scaling"

        self.y = None
        self.y_load = None
        self.y_latency = None

    def __repr__(self):
        """Returns this string when called as print(object)"""
        return """
APP                     opencraft
MODE                    %s
ENDPOINTS               %s""" % (
            ",".join(str(mode) for mode in self.modes),
            ",".join(str(endpoint) for endpoint in self.endpoints),
        )

    def generate(self):
        """Generate commands to run the benchmark based on the current settings"""
        # Differ in deployment modes
        for mode in self.modes:

            # Differ in #endpoints per worker
            for endpoint in self.endpoints:
                # No sense to use more than 1 endpoint in endpoint-only deployment mode
                if mode == "endpoint" and endpoint > 1:
                    continue

                command = [
                    "python3",
                    "continuum.py",
                    "-v",
                    "configuration/experiment_mc_endpoint_scaling/" + mode + str(endpoint) + ".cfg",
                ]
                command = [str(c) for c in command]

                run = {
                    "mode": mode,
                    "endpoints": endpoint,
                    "command": command,
                    "output": None,
                    "worker_time": None,
                }
                self.runs.append(run)

    def parse_output(self):
        """For all runs, get the worker runtime"""
        for run in self.runs:
            # Get the line containing the metrics
            # i = -10
            # for i, line in enumerate(run["output"]):
            #     if "Output in csv format" in line:
            #         break

            # # Get output based on type of run
            # raw_results = run["output"][i:][1]

            # # Get endpoint output, parse into dataframe
            # results1 = [x.split(",") for x in raw_results.split("\\n")]
            # results2 = [sub[1:] for sub in results1]
            # results_dict = dict(zip(results2[0], results2[1]))
            # for key in results_dict:
            #     if '[' in results_dict[key]:
            #         break
            #     try:
            #         run[key] = float(results_dict[key]) 
            #     except ValueError:
            #         continue

            # Response times
            i = -10
            for i, line in enumerate(run["output"]):
                if "Measurer spawned" in line:
                    break 
            
            run["dig_times"] = []
            run["place_times"] = []
            raw_results = run["output"][(i + 1):]
            i = 0
            while "----------------------------" not in raw_results[i]:
                if "Msr dig" in raw_results[i]: 
                    measured_value = str.strip(raw_results[i].split('Msr dig:')[1])
                    run["dig_times"].append(measured_value)
                elif "Msr place" in raw_results[i]:
                    measured_value = str.strip(raw_results[i].split('Msr place:')[1])
                    run["place_times"].append(measured_value)
                i += 1
            
            # Tick times
            i = -10
            for i, line in enumerate(run["output"]):
                if "Raw tick" in line:
                    break

            run["tick_times"] = []
            raw_results = run["output"][(i+1):]
            i = 0
            while i < len(raw_results) and "gather_worker_metrics" in raw_results[i]:
                measured_value = str.strip(raw_results[i].split()[-1])
                run["tick_times"].append(measured_value)
                i += 1


    def plot(self):
        """Plot the results from executed runs"""
        # set width of bar
        plt.rcParams.update({"font.size": 19})

        x = [run["endpoints"] for run in self.runs]

        y1 = [run["tick_times"] for run in self.runs]
        y1 = [[float(x) for x in lst] for lst in y1]

        # Find the maximum length of sublists
        max_length_y1 = max(len(sublist) for sublist in y1)

        # Pad sublists with NaN values to ensure equal length
        y1_padded = [sublist + [np.nan] * (max_length_y1 - len(sublist)) for sublist in y1]

        y1_stacked = np.vstack(y1_padded).tolist()

        logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)
        plt.figure(figsize=(10, 6))
        
        sbn.boxplot(data=y1_stacked, width = 0.3)
        plt.xticks(ticks=range(len(x)), labels=x)
        plt.yticks(np.arange(0, 1000, 100))
        plt.axhline(y=50, color='r', linestyle='-')
        plt.ylim(0, 400)
        plt.xlabel("Number of players")
        plt.ylabel("Tick duration [ms]")
        plt.grid(True)

        t = time.strftime("%Y-%m-%d_%H:%M:%S", time.gmtime())
        #plt.savefig("./logs/MCEndpointScalingTickRates_%s.pdf" % (t), bbox_inches="tight")
        plt.clf()

        y1 = next(filter(lambda run : run["endpoints"] == 80, self.runs))["tick_times"]
        y1 = [float(x) for x in y1]
        x1 = []
        x1.append(y1[0]) if y1[0] > 50 else x1.append(50)

        for elem in y1[1:]:
            x1.append(x1[-1] + elem) if elem > 50 else x1.append(x1[-1] + 50)
        x1 = [elem / 1000 for elem in x1]

        plt.plot(
            x1,
            y1,
            linewidth=1.5,
        )
        plt.axhline(y=50, color='r')
        plt.rcParams.update({"font.size": 19})
        plt.ylabel("Tick duration [ms]")
        plt.xlabel("Time [s]")
        plt.grid(True)

        plt.yticks(np.arange(0, 901, 100))
        plt.xticks(np.arange(0, 961, 120))

        #plt.xlim(0, 960)
        t = time.strftime("%Y-%m-%d_%H:%M:%S", time.gmtime())
        plt.savefig("./logs/MCEndpointScalingTicksOverTime80P_%s.pdf" % (t), bbox_inches="tight")
        plt.clf()

        # Response times plot  
        y1 = [run["dig_times"] for run in self.runs]
        y2 = [run["place_times"] for run in self.runs]

        y1 = [[int(x) for x in lst] for lst in y1]
        y2 = [[int(x) for x in lst] for lst in y2]

        # Function to pad sublists with NaNs to ensure equal length
        def pad_list(lst, length):
            return lst + [float('nan')] * (length - len(lst))

        # Pad sublists in y1 and y2
        max_length_y1 = max(len(sublist) for sublist in y1)
        max_length_y2 = max(len(sublist) for sublist in y2)
        max_sublist_length = max(max_length_y1, max_length_y2)
        y1_padded = [pad_list(sublist, max_sublist_length) for sublist in y1]
        y2_padded = [pad_list(sublist, max_sublist_length) for sublist in y2]

        df = pd.DataFrame({
            "Block digging": y1_padded,
            "Block placement": y2_padded,
            "Network latency": x
        })

        df_exploded = df.explode(column=["Block digging", "Block placement"])

        df_melted = pd.melt(df_exploded, id_vars=["Network latency"], var_name="Action", value_name="Values")

        #df_melted = df_melted.dropna()

        # Create boxplot using Seaborn
        logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)
        plt.figure(figsize=(10, 6))
        sbn.boxplot(x="Network latency", y="Values", hue="Action", data=df_melted, dodge=True, palette="pastel")
        plt.ylim(0, 1000)
        plt.yticks(np.arange(0, 1100, 100))
        plt.xlabel("Players")
        plt.ylabel("Response times [ms]")
        plt.grid(True)

        t = time.strftime("%Y-%m-%d_%H:%M:%S", time.gmtime())
        #plt.savefig("./logs/MCEndpointScalingLatencies_%s.pdf" % (t), bbox_inches="tight")

    def plot1(self):
        """Plot the results from executed runs"""
        # set width of bar
        plt.rcParams.update({"font.size": 22})
        _, ax1 = plt.subplots(1, 2, figsize=(24, 6))

        y1 = [run["ticks_mean"] for run in self.runs]
        y2 = [run["ticks_median"] for run in self.runs]
        y3 = [run["ticks_stdev"] for run in self.runs]
        x = self.endpoints
        
        ax1[0].plot(
            x,
            y1,
            linewidth=3.0,
            marker="o",
            markersize=12,
            label="Tick duration mean [ms]"
        )

        ax1[0].plot(
            x,
            y2,
            linewidth=3.0,
            marker="o",
            markersize=12,
            label="Tick duration median [ms]"
        )

        ax1[1].plot(
            x,
            y3,
            linewidth=3.0,
            marker="o",
            markersize=12,
            label="Tick duration standard dev"
        )

        # Set y axis: latency
        ax1[0].set_xlabel("Number of connected endpoints")
        ax1[0].set_xlim(25, 150)
        ax1[0].set_xticks(np.arange(0, 200, 25))

        ax1[0].set_ylabel("Tick duration statistics")
        ax1[0].set_yscale("linear")
        ax1[0].set_ylim(0, 50)
        ax1[0].set_yticks(np.arange(0, 50, 10))

        ax1[0].legend(loc="upper left", framealpha=1.0)

        #ax1.axhline(y=10, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[0].axhline(y=10, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[0].axhline(y=20, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[0].axhline(y=30, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[0].axhline(y=40, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[0].axhline(y=50, color="k", linestyle="-", linewidth=1, alpha=0.5)

        ax1[1].set_xlabel("Number of connected endpoints")
        ax1[1].set_xlim(25, 150)
        ax1[1].set_xticks(np.arange(0, 200, 25))

        ax1[1].set_ylabel("Tick duration standard deviation")
        ax1[1].set_yscale("linear")
        ax1[1].set_ylim(0, 150)
        ax1[1].set_yticks(np.arange(0, 150, 25))

        ax1[1].axhline(y=25, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[1].axhline(y=50, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[1].axhline(y=75, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[1].axhline(y=100, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[1].axhline(y=125, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[1].axhline(y=150, color="k", linestyle="-", linewidth=1, alpha=0.5)

        # Save
        t = time.strftime("%Y-%m-%d_%H:%M:%S", time.gmtime())
        plt.savefig("./logs/OCEndpointScaling_%s.pdf" % (t), bbox_inches="tight")

    def print_result(self):
        """Print results of runs as text"""
        for run in self.runs:
            logging.info(
                "Tick duration mean: %5i ms | \
                Tick duration median: %5i ms | \
                Tick duration stdev: %5i ms |",
                run["ticks_mean"],
                run["ticks_median"],
                run["ticks_stdev"],
            )

class CpuMemScaling(Experiment):
    """Experiment:
    Deploy a cloud worker with an Opencraft server, and vary the number of endpoints per run, in increments of 25.
    """

    def __init__(self, resume):
        Experiment.__init__(self, resume)

        self.cores = [0.5, 1, 2, 3, 4, 5, 6, 7]
        self.modes = ["linear"]
        self.log_directory = "oc_cpumem_scaling_40player"

    def __repr__(self):
        """Returns this string when called as print(object)"""
        return """
APP                     opencraft
CPU CORES               %s""" % (
            ",".join(str(core) for core in self.cores),
        )
    
    def generate(self):
        """Generate commands to run the benchmark based on the current settings"""
        # Differ in deployment modes
        for mode in self.modes:
            # Differ in #endpoints per worker
            for cores in self.cores:
                cores = int(cores * 100)
                command = [
                    "python3",
                    "continuum.py",
                    "-v",
                    "configuration/experiment_mc_cpumem_variation/cloud_0ms_cpu" + str(cores) + "_" + mode +".cfg",
                ]
                command = [str(c) for c in command]

                run = {
                    "cores": cores,
                    "command": command,
                    "output": None,
                }
                self.runs.append(run)

    def parse_output(self):
        """For all runs, get the worker runtime"""
        for run in self.runs:
            # Get the line containing the metrics
            i = -10
            for i, line in enumerate(run["output"]):
                if "Output in csv format" in line:
                    break

            # Get output based on type of run
            raw_results = run["output"][i:][1]

            # Get endpoint output, parse into dataframe
            results1 = [x.split(",") for x in raw_results.split("\\n")]
            results2 = [sub[1:] for sub in results1]
            results_dict = dict(zip(results2[0], results2[1]))
            for key in results_dict:
                if '[' in results_dict[key]:
                    break
                try:
                    run[key] = float(results_dict[key]) 
                except ValueError:
                    continue
                    
            # Tick times
            i = -10
            for i, line in enumerate(run["output"]):
                if "Raw tick" in line:
                    break

            run["tick_times"] = []
            raw_results = run["output"][(i+1):]
            i = 0
            while "gather_worker_metrics" in raw_results[i]:
                measured_value = str.strip(raw_results[i].split()[-1])
                run["tick_times"].append(measured_value)
                i += 1

            # Response times
            i = -10
            for i, line in enumerate(run["output"]):
                if "Measurer spawned" in line:
                    break
            
            run["dig_times"] = []
            run["place_times"] = []
            raw_results = run["output"][(i + 1):]
            i = 0
            while "----------------------------" not in raw_results[i]:
                if "Msr dig" in raw_results[i]: 
                    measured_value = str.strip(raw_results[i].split('Msr dig:')[1])
                    run["dig_times"].append(measured_value)
                elif "Msr place" in raw_results[i]:
                    measured_value = str.strip(raw_results[i].split('Msr place:')[1])
                    run["place_times"].append(measured_value)
                i += 1


    def plot(self):
        """Plot the results from executed runs"""
        # set width of bar
        plt.rcParams.update({"font.size": 19})

        x = [run["cores"] / 100 if run["cores"] / 100 < 1 else int(run["cores"] / 100) for run in self.runs]

        y1 = [run["tick_times"] for run in self.runs]
        y1 = [[float(x) for x in lst] for lst in y1]

        max_length_y1 = max(len(sublist) for sublist in y1)

        # Pad sublists with NaN values to ensure equal length
        y1_padded = [sublist + [np.nan] * (max_length_y1 - len(sublist)) for sublist in y1]

        y1_stacked = np.vstack(y1_padded).tolist()

        logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)
        plt.figure(figsize=(10, 6))
        
        sbn.boxplot(data=y1_stacked, width = 0.3)
        plt.xticks(ticks=range(len(x)), labels=x)
        plt.yticks(np.arange(0, 501, 50))
        plt.xlim(left=0.75)
        plt.ylim(0, 500)
        plt.xlabel("Server CPU Cores")
        plt.ylabel("Tick duration [ms]")
        plt.axhline(y=50, color='r')
        plt.grid(True)

        t = time.strftime("%Y-%m-%d_%H:%M:%S", time.gmtime())
        #plt.savefig("./logs/MCCpuMemScalingTickDur_%s.pdf" % (t), bbox_inches="tight")

        # Ticks over time
        plt.clf()

        plt.rcParams.update({"font.size": 19})
        y1 = next(filter(lambda run : run["cores"] == 200, self.runs))["tick_times"]
        y1 = [float(x) for x in y1]
        x1 = []
        x1.append(y1[0]) if y1[0] > 50 else x1.append(50)

        for elem in y1[1:]:
            x1.append(x1[-1] + elem) if elem > 50 else x1.append(x1[-1] + 50)
        x1 = [elem / 1000 for elem in x1]

        plt.plot(
            x1,
            y1,
            linewidth=1.5,
        )
        plt.axhline(y=50, color='r')
        plt.ylabel("Tick duration [ms]")
        plt.xlabel("Time [s]")
        plt.grid(True)

        plt.yticks(np.arange(0, 501, 50))
        plt.xticks(np.arange(0, 481, 120))

        #plt.xlim(0, 960)
        t = time.strftime("%Y-%m-%d_%H:%M:%S", time.gmtime())
        plt.savefig("./logs/MCCPUScalingTicksOverTime2C_%s.pdf" % (t), bbox_inches="tight")
        plt.clf()

        # Response times plot  
        y1 = [run["dig_times"] for run in self.runs]
        y2 = [run["place_times"] for run in self.runs]

        y1 = [[int(x) for x in lst] for lst in y1]
        y2 = [[int(x) for x in lst] for lst in y2]

        # Function to pad sublists with NaNs to ensure equal length
        def pad_list(lst, length):
            return lst + [float('nan')] * (length - len(lst))

        # Pad sublists in y1 and y2
        max_length_y1 = max(len(sublist) for sublist in y1)
        max_length_y2 = max(len(sublist) for sublist in y2)
        max_sublist_length = max(max_length_y1, max_length_y2)
        y1_padded = [pad_list(sublist, max_sublist_length) for sublist in y1]
        y2_padded = [pad_list(sublist, max_sublist_length) for sublist in y2]

        df = pd.DataFrame({
            "Block digging": y1_padded,
            "Block placement": y2_padded,
            "Network latency": x
        })

        df_exploded = df.explode(column=["Block digging", "Block placement"])

        df_melted = pd.melt(df_exploded, id_vars=["Network latency"], var_name="Action", value_name="Values")

        #df_melted = df_melted.dropna()

        # Create boxplot using Seaborn
        logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)
        plt.figure(figsize=(10, 6))
        sbn.boxplot(x="Network latency", y="Values", hue="Action", data=df_melted, dodge=True, palette="pastel")
        plt.ylim(0, 1000)
        plt.yticks(np.arange(0, 1001, 100))
        plt.xlim(left=0.50)
        plt.xlabel("CPU Cores")
        plt.ylabel("Response time [ms]")
        plt.grid(True)

        t = time.strftime("%Y-%m-%d_%H:%M:%S", time.gmtime())
        #plt.savefig("./logs/MCCPUScalingLatencies_%s.pdf" % (t), bbox_inches="tight")

    def print_result(self):
        """Print results of runs as text"""
        for run in self.runs:
            logging.info(
                "Tick duration mean: %5i ms | \
                Tick duration median: %5i ms | \
                Tick duration stdev: %5i ms |",
                run["ticks_mean"],
                run["ticks_median"],
                run["ticks_stdev"],
            )

def main(args):
    if (args.experiment == "EndpointScaling"):
        exp = EndpointScaling(args.resume)
    elif (args.experiment == "LatencyVariation"):
        exp = LatencyCPUVariation(args.resume)
    else:
        exp = CpuMemScaling(args.resume)

    logging.info(exp)
    exp.generate()
    exp.check_resume()
    exp.run_commands()
    exp.parse_output()
    exp.plot()
    exp.print_result()

if __name__ == "__main__":
    # Get input arguments, and validate those arguments
    parser_obj = argparse.ArgumentParser()

    parser_obj.add_argument("-v", "--verbose", action="store_true", help="increase verbosity level")
    parser_obj.add_argument(
        "-r",
        "--resume",
        type=lambda s: datetime.datetime.strptime(s, "%Y-%m-%d_%H:%M:%S"),
        help='Resume a previous figure replication from datetime "YYYY-MM-DD_HH:mm:ss"',
    )
    parser_obj.add_argument(
        "experiment",
        type=str,
        choices=["EndpointScaling", "LatencyVariation", "CpuMemScaling"],
    )
    arguments = parser_obj.parse_args()

    enable_logging(arguments.verbose)
    main(arguments)