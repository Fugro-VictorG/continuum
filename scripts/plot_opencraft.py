import math
import time
import argparse
import sys
import logging
import subprocess
import datetime
import os

from io import StringIO

import matplotlib.pyplot as plt
import matplotlib.ticker as mtick
import matplotlib.patches as mpatches
import numpy as np
import pandas as pd

from matplotlib.ticker import ScalarFormatter
from matplotlib.ticker import NullFormatter
from matplotlib.ticker import MaxNLocator

def enable_logging(verbose):
    """Enable logging"""
    # Set parameters
    new_level = logging.INFO
    if verbose:
        new_level = logging.DEBUG

    new_format = "[%(asctime)s %(filename)20s:%(lineno)4s - %(funcName)25s() ] %(message)s"
    logging.basicConfig(format=new_format, level=new_level, datefmt="%Y-%m-%d %H:%M:%S")

    logging.info("Logging has been enabled")

def execute(command):
    """Execute a process using the subprocess library,
    and return the output/error or the process

    Args:
        command (list(str)): Command to be executed.

    Returns:
        (list(str), list(str)): Return the output and error generated by this process.
    """
    logging.info(" ".join(command))

    with subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE) as process:
        output = [line.decode("utf-8") for line in process.stdout.readlines()]
        error = [line.decode("utf-8") for line in process.stderr.readlines()]

    return output, error

class Experiment:
    """Experiment template / super class"""

    def __init__(self, resume):
        self.resume = resume
        self.runs = []

    def check_resume(self):
        """If the resume argument is given, get the first x log files >= the resume date,
        and use their output instead of re-running the experiment.
        """
        if self.resume is None:
            return

        log_location = "./logs"
        logs = [f for f in os.listdir(log_location) if f.endswith(".log")]
        logs.sort()
        exp_i = 0

        for log in logs:
            splits = log.split("_")
            dt = splits[0] + "_" + splits[1]
            dt = datetime.datetime.strptime(dt, "%Y-%m-%d_%H:%M:%S")

            if dt >= self.resume:
                path = os.path.join(log_location, log)
                logging.info("File %s for experiment run %i", path, exp_i)

                with open(path, "r", encoding="utf-8") as f:
                    output = f.readlines()
                    f.close()

                self.runs[exp_i]["output"] = output
                exp_i += 1

                # We have all logs needed
                if exp_i == len(self.runs):
                    break

    def run_commands(self):
        """Execute all generated commands"""
        for run in self.runs:
            if run["command"] == []:
                continue

            # Skip runs where we got output with --resume
            if run["output"] is not None:
                logging.info("Skip command: %s", " ".join(run["command"]))
                continue

            output, error = execute(run["command"])

            logging.debug("------------------------------------")
            logging.debug("OUTPUT")
            logging.debug("------------------------------------")
            logging.debug("\n%s", "".join(output[-5:]))

            if error != []:
                logging.debug("------------------------------------")
                logging.debug("ERROR")
                logging.debug("------------------------------------")
                logging.debug("\n%s", "".join(error))
                sys.exit()

            logging.debug("------------------------------------")

            # Get output from log file
            logpath = output[0].rstrip().split("and file ")[-1]
            with open(logpath, "r", encoding="utf-8") as f:
                output = f.readlines()
                run["output"] = output
                f.close()

class LatencyCPUVariation(Experiment):
    """Experiment:
    Deploy 1 cloud worker and 1 endpoint, and vary latency from 0ms to 100ms in steps of 10
    Also vary the CPU cores / memory from 0.5 (GB) to 8.0 (GB)

    So:
    - Run with minimal cloud deployment
    - Change latency from 0ms to 100ms between cloud and endpoint in steps of 10ms
    - Change application CPU and memory from 0.5 to 8.0 in power of 2 steps
    """

    def __init__(self, resume):
        Experiment.__init__(self, resume)

        self.latency = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]

        # CPU x quota: 0.5 | 1.0 | 2.0 | 4.0 | 8.0
        self.cpu = [2]#[1, 1, 2, 4, 8]
        self.memory = [2]#[0.5, 1.0, 2.0, 4.0, 8.0]
        self.quota = [1]#[0.5, 1.0, 1.0, 1.0, 1.0]

        self.y = None

    def __repr__(self):
        """Returns this string when called as print(object)"""
        return """
APP                     opencraft
LATENCY                 %s
CPU CORES               %s
MEMORY (GB)             %s
QUOTA                   %s""" % (
            ",".join(str(latency) for latency in self.latency),
            ",".join(str(cpu) for cpu in self.cpu),
            ",".join(str(memory) for memory in self.memory),
            ",".join(str(quota) for quota in self.quota),
        )

    def generate(self):
        """Generate commands to run the benchmark based on the current settings"""
        # Differ in deployment modes
        for latency in self.latency:
            for cpu, memory, quota in zip(self.cpu, self.memory, self.quota):
                cpu_quota = cpu * quota
                if cpu_quota != memory:
                    logging.error("ERROR: cpu x quota (%f) != memory (%f)", cpu_quota, memory)
                    sys.exit()

                if cpu_quota >= 1:
                    cpu_str = "%s00" % (int(cpu_quota))
                elif cpu_quota < 1:
                    cpu_str = "0%s" % (int(cpu_quota * 100))

                config = "cloud_%ims_cpu%s.cfg" % (latency, cpu_str)
                command = [
                    "python3",
                    "continuum.py",
                    "-v",
                    "configuration/experiment_latency_var_oc/" + config,
                ]
                command = [str(c) for c in command]

                run = {
                    "cpu_quota_memory": cpu_quota,
                    "network_latency": latency,
                    "command": command,
                    "output": None,
                    "latency": None,
                }
                self.runs.append(run)

    def parse_output(self):
        """For all runs, get the worker runtime"""
        for run in self.runs:
            # Get the line containing the metrics
            i = -10
            for i, line in enumerate(run["output"]):
                if "Output in csv format" in line:
                    break

            # Get output based on type of run
            raw_results = run["output"][i:][1]

            # Get endpoint output, parse into dataframe
            results1 = [x.split(",") for x in raw_results.split("\\n")]
            results2 = [sub[1:] for sub in results1]
            results_dict = dict(zip(results2[0], results2[1]))
            for key in results_dict:
                run[key] = float(results_dict[key])

    def plot(self):
        """Plot the results from executed runs"""
        # set width of bar
        plt.rcParams.update({"font.size": 22})
        _, ax1 = plt.subplots(figsize=(12, 6))

        x = [run["network_latency"] for run in self.runs if run["cpu_quota_memory"] == 2]

        for cpu, quota in zip(self.cpu, self.quota):
            cpu_quota = cpu * quota
            y1 = [run["response_time_dig_mean"] for run in self.runs if run["cpu_quota_memory"] == cpu_quota]
            y2 = [run["response_time_place_mean"] for run in self.runs if run["cpu_quota_memory"] == cpu_quota]

            ax1.plot(
                x,
                y1,
                linewidth=3.0,
                marker="o",
                markersize=12,
                label="Block digging",
            )

            ax1.plot(
                x,
                y2,
                linewidth=3.0,
                marker="o",
                markersize=12,
                label="Block placement"
            )

        # Set y axis: latency
        ax1.set_ylabel("Average response time [ms]")
        ax1.set_yscale("linear")
        ax1.set_ylim(10, 300)
        ax1.set_yticks(np.arange(0, 325, 25))

        ax1.set_xlabel("Network latency between cloud and endpoint [ms]")
        ax1.set_xlim(0, 100)
        ax1.set_xticks(np.arange(0, 110, 10))

        ax1.legend(loc="best", framealpha=1.0, ncol=3, bbox_to_anchor=[0.5, 0.37])

        #ax1.axhline(y=10, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=100, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=200, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=300, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=400, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=500, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=600, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=700, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=800, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=900, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=1000, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1.axhline(y=1100, color="k", linestyle="-", linewidth=1, alpha=0.5)

        # Save
        t = time.strftime("%Y-%m-%d_%H:%M:%S", time.gmtime())
        plt.savefig("./logs/OCLatencyCPUVariation_%s.pdf" % (t), bbox_inches="tight")

    def print_result(self):
        """Print results of runs as text"""
        for run in self.runs:
            logging.info(
                "Tick duration avg: %5i ms | \
                Tick duration stdev: %5i ms | \
CPU Cores x Quota == Memory: %5f | \
Response time dig mean: %5i ms | \
Response time dig median: %5i ms | \
Response time dig stdev: %5i | \
Response time place mean: %5i ms | \
Response time place median: %5i ms | \
Response time place stdev: %5i",
                run["ticks_avg"],
                run["ticks_stdev"],
                run["cpu_quota_memory"],
                run["response_time_dig_mean"],
                run["response_time_dig_median"],
                run["response_time_dig_stdev"],
                run["response_time_place_mean"],
                run["response_time_place_median"],
                run["response_time_place_stdev"]
            )
            
class EndpointScaling(Experiment):
    """Experiment:
    Deploy 1 cloud worker and 1 endpoint, and vary latency from 0ms to 100ms in steps of 10
    Also vary the CPU cores / memory from 0.5 (GB) to 8.0 (GB)

    So:
    - Run with minimal cloud deployment
    - Change latency from 0ms to 100ms between cloud and endpoint in steps of 10ms
    - Change application CPU and memory from 0.5 to 8.0 in power of 2 steps
    """

    def __init__(self, resume):
        Experiment.__init__(self, resume)

        self.modes = ["cloud"]#, "edge", "endpoint"]
        self.cores = [4]
        self.endpoints = [25, 50, 75, 100, 125, 150]

        self.y = None
        self.y_load = None
        self.y_latency = None

    def __repr__(self):
        """Returns this string when called as print(object)"""
        return """
APP                     opencraft
MODE                    %s
ENDPOINTS               %s""" % (
            ",".join(str(mode) for mode in self.modes),
            ",".join(str(endpoint) for endpoint in self.endpoints),
        )

    def generate(self):
        """Generate commands to run the benchmark based on the current settings"""
        # Differ in deployment modes
        for mode in self.modes:
            if mode == "cloud":
                config = "cloud_endpoint"
                cores = self.cores[0]
            elif mode == "edge":
                config = "edge_endpoint"
                cores = self.cores[1]
            else:
                config = "endpoint"
                cores = self.cores[2]

            # Differ in #endpoints per worker
            for endpoint in self.endpoints:
                # No sense to use more than 1 endpoint in endpoint-only deployment mode
                if mode == "endpoint" and endpoint > 1:
                    continue

                command = [
                    "python3",
                    "continuum.py",
                    "-v",
                    "configuration/experiment_oc_endpoint_scaling/" + config + str(endpoint) + ".cfg",
                ]
                command = [str(c) for c in command]

                run = {
                    "mode": mode,
                    "cores": cores,
                    "endpoints": endpoint,
                    "command": command,
                    "output": None,
                    "worker_time": None,
                }
                self.runs.append(run)

    def parse_output(self):
        """For all runs, get the worker runtime"""
        for run in self.runs:
            # Get the line containing the metrics
            i = -10
            for i, line in enumerate(run["output"]):
                if "Output in csv format" in line:
                    break

            # Get output based on type of run
            raw_results = run["output"][i:][1]

            # Get endpoint output, parse into dataframe
            results1 = [x.split(",") for x in raw_results.split("\\n")]
            results2 = [sub[1:] for sub in results1]
            results_dict = dict(zip(results2[0], results2[1]))
            for key in results_dict:
                run[key] = float(results_dict[key]) if results_dict[key] else ''

    def plot(self):
        """Plot the results from executed runs"""
        # set width of bar
        plt.rcParams.update({"font.size": 22})
        _, ax1 = plt.subplots(1, 2, figsize=(24, 6))

        y1 = [run["ticks_mean"] for run in self.runs]
        y2 = [run["ticks_median"] for run in self.runs]
        y3 = [run["ticks_stdev"] for run in self.runs]
        x = self.endpoints
        
        ax1[0].plot(
            x,
            y1,
            linewidth=3.0,
            marker="o",
            markersize=12,
            label="Tick duration mean [ms]"
        )

        ax1[0].plot(
            x,
            y2,
            linewidth=3.0,
            marker="o",
            markersize=12,
            label="Tick duration median [ms]"
        )

        ax1[1].plot(
            x,
            y3,
            linewidth=3.0,
            marker="o",
            markersize=12,
            label="Tick duration standard dev"
        )

        # Set y axis: latency
        ax1[0].set_xlabel("Number of connected endpoints")
        ax1[0].set_xlim(25, 150)
        ax1[0].set_xticks(np.arange(0, 200, 25))

        ax1[0].set_ylabel("Tick duration statistics")
        ax1[0].set_yscale("linear")
        ax1[0].set_ylim(0, 50)
        ax1[0].set_yticks(np.arange(0, 50, 10))

        ax1[0].legend(loc="upper left", framealpha=1.0)

        #ax1.axhline(y=10, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[0].axhline(y=10, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[0].axhline(y=20, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[0].axhline(y=30, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[0].axhline(y=40, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[0].axhline(y=50, color="k", linestyle="-", linewidth=1, alpha=0.5)

        ax1[1].set_xlabel("Number of connected endpoints")
        ax1[1].set_xlim(25, 150)
        ax1[1].set_xticks(np.arange(0, 200, 25))

        ax1[1].set_ylabel("Tick duration standard deviation")
        ax1[1].set_yscale("linear")
        ax1[1].set_ylim(0, 150)
        ax1[1].set_yticks(np.arange(0, 150, 25))

        ax1[1].axhline(y=25, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[1].axhline(y=50, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[1].axhline(y=75, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[1].axhline(y=100, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[1].axhline(y=125, color="k", linestyle="-", linewidth=1, alpha=0.5)
        ax1[1].axhline(y=150, color="k", linestyle="-", linewidth=1, alpha=0.5)

        # Save
        t = time.strftime("%Y-%m-%d_%H:%M:%S", time.gmtime())
        plt.savefig("./logs/OCEndpointScaling_%s.pdf" % (t), bbox_inches="tight")

    def print_result(self):
        """Print results of runs as text"""
        for run in self.runs:
            logging.info(
                "Tick duration mean: %5i ms | \
                Tick duration median: %5i ms | \
                Tick duration stdev: %5i ms | \
Response time dig mean: %5i ms | \
Response time dig median: %5i ms | \
Response time dig stdev: %5i | \
Response time place mean: %5i ms | \
Response time place median: %5i ms | \
Response time place stdev: %5i",
                run["ticks_mean"],
                run["ticks_median"],
                run["ticks_stdev"],
                run["response_time_dig_mean"],
                run["response_time_dig_median"],
                run["response_time_dig_stdev"],
                run["response_time_place_mean"],
                run["response_time_place_median"],
                run["response_time_place_stdev"]
            )

def main(args):
    exp = EndpointScaling(args.resume)

    logging.info(exp)
    exp.generate()
    exp.check_resume()
    exp.run_commands()
    exp.parse_output()
    exp.plot()
    exp.print_result()

if __name__ == "__main__":
    # Get input arguments, and validate those arguments
    parser_obj = argparse.ArgumentParser()

    parser_obj.add_argument("-v", "--verbose", action="store_true", help="increase verbosity level")
    parser_obj.add_argument(
        "-r",
        "--resume",
        type=lambda s: datetime.datetime.strptime(s, "%Y-%m-%d_%H:%M:%S"),
        help='Resume a previous figure replication from datetime "YYYY-MM-DD_HH:mm:ss"',
    )
    arguments = parser_obj.parse_args()

    enable_logging(arguments.verbose)
    main(arguments)